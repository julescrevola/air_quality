{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import BayesianRidge, HuberRegressor, PassiveAggressiveRegressor, TheilSenRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "path = \"../data/train.csv\"\n",
    "df = pd.read_csv(path, parse_dates=[0])\n",
    "\n",
    "df_weather1 = pd.read_csv(\"https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/HOR/H_75_previous-2020-2022.csv.gz\", sep=';')\n",
    "df_weather2 = pd.read_csv(\"https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/HOR/H_75_latest-2023-2024.csv.gz\", sep=';')\n",
    "weather = pd.concat([df_weather1, df_weather2])\n",
    "\n",
    "holidays_path = \"../data/fr-en-calendrier-scolaire.csv\"\n",
    "holidays = pd.read_csv(holidays_path, sep=\";\")\n",
    "\n",
    "traffic_path = \"../data/traffic_data.csv\"\n",
    "traffic = pd.read_csv(traffic_path, sep=\";\")\n",
    "\n",
    "final_test = pd.read_csv(\"../data/test.csv\", parse_dates=[0]).rename(columns={\"id\": \"date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = pd.read_csv(\"../data/test.csv\", parse_dates=[0]).rename(columns={\"id\": \"date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eng:\n",
    "    def __init__(self, df, weather, traffic, holidays):\n",
    "        self.df = df\n",
    "        self.df = self.df.rename(columns={\"id\": \"date\"})\n",
    "        self.df = self.df.drop_duplicates()\n",
    "\n",
    "        self.external_database(weather, traffic)\n",
    "        self.additional_data(holidays)\n",
    "        self.date_features()\n",
    "        \n",
    "\n",
    "    def external_database(self, weather, traffic):\n",
    "        \n",
    "        ##### Weather #####\n",
    "        \n",
    "        self.weather = weather\n",
    "\n",
    "        # Dropping empty columns\n",
    "        self.weather = self.weather.drop(\n",
    "            columns=['FF2', 'QFF2', 'DD2', 'QDD2', 'FXI2', 'QFXI2', 'DXI2', 'QDXI2', 'HXI2', 'QHXI2', 'DXI3S',\n",
    "                                      'DHUMEC', 'QDHUMEC', 'GEOP', 'QGEOP', 'N', 'QN', 'NBAS', 'QNBAS', 'CL', 'QCL', 'CM', 'QCM',\n",
    "                                      'CH', 'QCH', 'N1', 'QN1', 'C1', 'QC1', 'B1', 'QB1', 'N2', 'QN2', 'C2', 'QC2', 'B2', 'QB2',\n",
    "                                      'N3', 'QN3', 'C3', 'QC3', 'B3', 'QB3', 'N4', 'QN4', 'C4', 'QC4', 'B4', 'QB4', 'W1', 'QW1',\n",
    "                                      'W2', 'QW2', 'SOL', 'QSOL', 'SOLNG', 'QSOLNG', 'TMER', 'QTMER', 'VVMER', 'QVVMER', 'ETATMER',\n",
    "                                      'QETATMER', 'DIRHOULE', 'QDIRHOULE', 'HVAGUE', 'QHVAGUE', 'PVAGUE', 'QPVAGUE', 'HNEIGEF', 'QHNEIGEF',\n",
    "                                      'TSNEIGE', 'QTSNEIGE', 'TUBENEIGE', 'QTUBENEIGE', 'HNEIGEFI3', 'QHNEIGEFI3', 'HNEIGEFI1', 'QHNEIGEFI1',\n",
    "                                      'ESNEIGE', 'QESNEIGE', 'CHARGENEIGE', 'QCHARGENEIGE', 'DIR', 'QDIR', 'DIR2', 'QDIR2', 'DIF', 'QDIF',\n",
    "                                      'DIF2', 'QDIF2', 'UV', 'QUV', 'UV2', 'QUV2', 'UV_INDICE', 'QUV_INDICE', 'INFRAR', 'QINFRAR', 'INFRAR2',\n",
    "                                      'QINFRAR2', 'TLAGON', 'QTLAGON', 'TVEGETAUX', 'QTVEGETAUX', 'ECOULEMENT', 'QECOULEMENT', 'NUM_POSTE',\n",
    "                                      'NOM_USUEL', 'LAT', 'LON', 'DRR1', 'FF', 'QFF', 'DD', 'QDD', 'FXY', 'QFXY', 'DXY', 'QDXY', 'QHXY', 'FXI',\n",
    "                                      'QFXI', 'DXI', 'QDXI', 'QHXI', 'FXI3S', 'QFXI3S', 'QDXI3S', 'QHFXI3S', 'TD', 'QTD', 'T10', 'QT10', 'T20',\n",
    "                                      'QT20', 'T50', 'QT50', 'T100', 'QT100', 'TNSOL', 'QTNSOL', 'TN50', 'QTN50', 'TCHAUSSEE', 'QTCHAUSSEE',\n",
    "                                      'U', 'QU', 'UN', 'QUN', 'QHUN', 'UX', 'QUX', 'QHUX', 'DHUMI40', 'QDHUMI40', 'DHUMI80', 'QDHUMI80', 'TSV',\n",
    "                                      'QTSV', 'PMER', 'QPMER', 'PSTAT', 'QPSTAT', 'PMERMIN', 'QPMERMIN', 'VV', 'QVV', 'DVV200', 'QDVV200', 'WW',\n",
    "                                      'QWW', 'NEIGETOT', 'QNEIGETOT', 'GLO', 'QGLO', 'GLO2', 'QGLO2', 'INS', 'QINS', 'INS2', 'QINS2', 'QDRR1']\n",
    "                                      )\n",
    "        \n",
    "        # Grouping by date to sum and average values across all meteo stations\n",
    "        self.weather[\"date\"] = pd.to_datetime(self.weather[\"AAAAMMJJHH\"], format=\"%Y%m%d%H\")\n",
    "        self.weather = self.weather.drop(columns=[\"AAAAMMJJHH\", \"HXI\", \"HXY\", \"HFXI3S\", \"HTN\", \"HTX\", \"HUN\", \"HUX\"])\n",
    "\n",
    "        self.avg = self.weather.drop(\n",
    "            columns=['RR1']\n",
    "            ).groupby(\"date\").mean().reset_index()\n",
    "\n",
    "        self.tot = self.weather.drop(\n",
    "            columns=['TX', 'T', 'QTX', 'DG', 'QT', 'QHTN', 'QHTX', 'TN', 'QDG', 'QTN']\n",
    "            ).groupby(\"date\").sum().reset_index()\n",
    "\n",
    "        self.weather = self.weather.drop_duplicates(subset=[\"date\"])\n",
    "\n",
    "        self.df = self.df.merge(self.weather, on=\"date\", how=\"left\")\n",
    "\n",
    "        # Filling missing values for weather data with their mean as there are very few\n",
    "        self.is_na = self.df.isna().sum()\n",
    "\n",
    "        for col in self.is_na.index:\n",
    "            if self.is_na[col] > 0:\n",
    "                self.df[col] = self.df[col].fillna(self.df[col].mean())\n",
    "        \n",
    "\n",
    "        ##### Traffic #####\n",
    "        \n",
    "        # traffic.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "        traffic[\"date\"] = pd.to_datetime(traffic[\"date\"])\n",
    "\n",
    "        traffic = traffic.drop_duplicates(subset=[\"date\"])\n",
    "        linear_int2 = traffic[[\"date\", 'flow', 'occupation_rate']]\n",
    "        linear_int2 = linear_int2.set_index(\"date\")\n",
    "        new_features2 = linear_int2.resample('1h').interpolate(\"linear\")\n",
    "\n",
    "        self.df = self.df.merge(new_features2, on=\"date\", how=\"left\")\n",
    "\n",
    "        self.df[\"flow\"] = self.df[\"flow\"].fillna(self.df[\"flow\"].mean())\n",
    "        self.df[\"occupation_rate\"] = self.df[\"occupation_rate\"].fillna(self.df[\"occupation_rate\"].mean())\n",
    "        \n",
    "\n",
    "    def date_features(self):\n",
    "        # Create new date features\n",
    "        self.df['day'] = self.df['date'].dt.day\n",
    "        self.df['month'] = self.df['date'].dt.month\n",
    "        self.df['year'] = self.df['date'].dt.year\n",
    "        self.df['hour'] = self.df['date'].dt.hour\n",
    "        self.df['weekday'] = self.df['date'].dt.weekday \n",
    "        \n",
    "        self.df[\"weekend\"] = self.df['weekday'].isin([5, 6])\n",
    "        \n",
    "\n",
    "    def additional_data(self, holidays):\n",
    "    \n",
    "        ###### Lockdown variable ######\n",
    "        \n",
    "        # Lockdown in Paris\n",
    "        start_date = pd.to_datetime('2020-10-31')\n",
    "        end_date = pd.to_datetime('2020-12-14')\n",
    "        start_date1 = pd.to_datetime('2021-04-04')\n",
    "        end_date1 = pd.to_datetime('2021-05-02')\n",
    "        \n",
    "        # Assign 1 if the date is within the specified range, otherwise 0\n",
    "        self.df['lockdown'] = self.df['date'].apply(lambda x: 1 if ((start_date <= x <= end_date) or (start_date1 <= x <= end_date1)) else 0)\n",
    "        \n",
    "\n",
    "        ###### Curfews variable ######\n",
    "        \n",
    "        # Curfew date range (+1 hour because the data is the cumulative of the previous)\n",
    "        curfew_periods = [\n",
    "            (pd.to_datetime('2020-10-17 22:00'), pd.to_datetime('2020-10-29 07:00')),\n",
    "            (pd.to_datetime('2020-12-16 21:00'), pd.to_datetime('2021-01-15 07:00')),\n",
    "            (pd.to_datetime('2021-01-16 19:00'), pd.to_datetime('2021-03-20 07:00')),\n",
    "            (pd.to_datetime('2021-03-21 20:00'), pd.to_datetime('2021-04-02 07:00')),\n",
    "            (pd.to_datetime('2021-05-19 22:00'), pd.to_datetime('2021-06-08 07:00')),\n",
    "            (pd.to_datetime('2021-06-09 23:00'), pd.to_datetime('2021-06-20 07:00'))\n",
    "        ]\n",
    "\n",
    "        # Create a new column 'Curfew' and assign 1 if the date is within the specified range, otherwise 0\n",
    "\n",
    "        self.df['curfew'] = 0  # Initialize the Curfew column\n",
    "\n",
    "        # Loop through curfew periods and set Curfew column accordingly\n",
    "        for start_time, end_time in curfew_periods:\n",
    "            mask = self.df[self.df['date'].between(start_time, end_time)]\n",
    "            mask = mask[(mask[\"date\"].dt.hour > start_time.hour) | (mask[\"date\"].dt.hour < end_time.hour)]\n",
    "            self.df.loc[mask.index, 'curfew'] = 1\n",
    "            \n",
    "        \n",
    "        ###### Holidays variable ######\n",
    "\n",
    "        # Consider only metropolitan areas\n",
    "        holidays = holidays[holidays[\"Zones\"].isin([\"Zone C\"])]\n",
    "\n",
    "        # Consider only relevant years\n",
    "        holidays = holidays[holidays[\"annee_scolaire\"].isin([\"2020-2021\", \"2021-2022\"])]\n",
    "\n",
    "        # Distinguish for holidays in Paris or not\n",
    "        holidays['Holidays in Paris'] = 1\n",
    "\n",
    "        holidays.drop([\"Académies\",\"Population\", \"Zones\"], axis=1, inplace = True)\n",
    "\n",
    "        # Convert to same date format\n",
    "        holidays['Date de début'] = holidays['Date de début'].apply(lambda x: x[0:10]+' '+x[11:19])\n",
    "        holidays['Date de fin'] = holidays['Date de fin'].apply(lambda x: x[0:10]+' '+x[11:19])\n",
    "\n",
    "        holidays[\"Date de début\"] = pd.to_datetime(holidays[\"Date de début\"], format='%Y-%m-%d %H:%M:%S')\n",
    "        holidays[\"Date de fin\"] = pd.to_datetime(holidays[\"Date de fin\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Remove holidays starting after final date of dataset\n",
    "        holidays = holidays[holidays[\"Date de début\"].dt.year != 2022]\n",
    "\n",
    "        # Remove summer holidays\n",
    "        holidays = holidays[holidays[\"Description\"] != \"Vacances d'Été\"]\n",
    "        holidays.drop([\"Description\",\"annee_scolaire\"], axis=1, inplace=True)\n",
    "\n",
    "        # Drop same holidays\n",
    "        holidays = holidays.drop_duplicates(subset=['Date de début', 'Date de fin'], keep='first')\n",
    "\n",
    "        # Create holidays date ranges \n",
    "        ranges = []\n",
    "        for x in holidays[[\"Date de début\",\"Date de fin\"]].values:\n",
    "            ranges.append(pd.date_range(x[0], x[1], freq=\"h\"))\n",
    "            \n",
    "            \n",
    "        def is_date_within_ranges(date, ranges):\n",
    "            for date_range in ranges:\n",
    "                if date_range[0] <= date <= date_range[-1]:\n",
    "                    return 1\n",
    "            return 0\n",
    "\n",
    "        # Apply the function to create a new column indicating whether the date is within any holiday range\n",
    "        self.df['holiday'] = self.df['date'].apply(lambda x: is_date_within_ranges(x, ranges))\n",
    "        \n",
    "        \n",
    "        ###### Rush hour ########\n",
    "        def is_rush_hour(x):\n",
    "            if ((7 <= x.hour <= 9) or (16 <= x.hour <= 19)) and x.weekday != 5 and x.weekday != 6:\n",
    "                return 1\n",
    "            elif (x.weekday == 5 or x.weekday == 6) and (16 <= x.hour <= 19):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "        self.df['rush_hour'] = self.df['date'].apply(lambda x: is_rush_hour(x))\n",
    "        \n",
    "\n",
    "    def output(self, test: bool=False):\n",
    "\n",
    "        if test == False:\n",
    "\n",
    "            # Using interpolation to fill in missing values before adding lag features\n",
    "            linear_int = self.df[[\"date\", \"valeur_NO2\", \"valeur_CO\", \"valeur_O3\", \"valeur_PM10\", \"valeur_PM25\"]]\n",
    "            linear_int = linear_int.set_index(\"date\")\n",
    "            new_features = linear_int.resample('1h').interpolate(\"linear\")\n",
    "\n",
    "            self.df = self.df.merge(new_features, on=\"date\", how=\"left\")\n",
    "            self.df = self.df.rename(columns={'valeur_NO2_y': 'valeur_NO2', 'valeur_CO_y': 'valeur_CO', 'valeur_O3_y': 'valeur_O3', 'valeur_PM10_y': 'valeur_PM10',\n",
    "                'valeur_PM25_y': 'valeur_PM25'})\n",
    "            self.df = self.df.drop(['valeur_NO2_x', 'valeur_CO_x', 'valeur_O3_x', 'valeur_PM10_x',\n",
    "                'valeur_PM25_x'], axis=1)\n",
    "            \n",
    "            # Generating lag columns\n",
    "            self.df[\"valeur_NO2_lag1\"] = self.df['valeur_NO2'].shift(1)\n",
    "            self.df[\"valeur_CO_lag1\"] = self.df['valeur_CO'].shift(1)\n",
    "            self.df[\"valeur_O3_lag1\"] = self.df['valeur_O3'].shift(1)\n",
    "            self.df[\"valeur_PM10_lag1\"] = self.df['valeur_PM10'].shift(1)\n",
    "            self.df[\"valeur_PM25_lag1\"] = self.df['valeur_PM25'].shift(1)\n",
    "\n",
    "            self.df[\"valeur_NO2_lag12\"] = self.df['valeur_NO2'].shift(12)\n",
    "            self.df[\"valeur_CO_lag12\"] = self.df['valeur_CO'].shift(12)\n",
    "            self.df[\"valeur_O3_lag12\"] = self.df['valeur_O3'].shift(12)\n",
    "            self.df[\"valeur_PM10_lag12\"] = self.df['valeur_PM10'].shift(12)\n",
    "            self.df[\"valeur_PM25_lag12\"] = self.df['valeur_PM25'].shift(12)\n",
    "\n",
    "            self.df[\"valeur_NO2_lag24\"] = self.df['valeur_NO2'].shift(24)\n",
    "            self.df[\"valeur_CO_lag24\"] = self.df['valeur_CO'].shift(24)\n",
    "            self.df[\"valeur_O3_lag24\"] = self.df['valeur_O3'].shift(24)\n",
    "            self.df[\"valeur_PM10_lag24\"] = self.df['valeur_PM10'].shift(24)\n",
    "            self.df[\"valeur_PM25_lag24\"] = self.df['valeur_PM25'].shift(24)\n",
    "\n",
    "            # Filling NaNs\n",
    "            self.df['valeur_NO2_lag1'] = self.df['valeur_NO2_lag1'].fillna(self.df['valeur_NO2'])\n",
    "            self.df['valeur_CO_lag1'] = self.df['valeur_CO_lag1'].fillna(self.df['valeur_CO'])\n",
    "            self.df['valeur_O3_lag1'] = self.df['valeur_O3_lag1'].fillna(self.df['valeur_O3'])\n",
    "            self.df['valeur_PM10_lag1'] = self.df['valeur_PM10_lag1'].fillna(self.df['valeur_PM10'])\n",
    "            self.df['valeur_PM25_lag1'] = self.df['valeur_PM25_lag1'].fillna(self.df['valeur_PM25'])\n",
    "\n",
    "            self.df['valeur_NO2_lag12'] = self.df['valeur_NO2_lag12'].fillna(self.df['valeur_NO2'])\n",
    "            self.df['valeur_CO_lag12'] = self.df['valeur_CO_lag12'].fillna(self.df['valeur_CO'])\n",
    "            self.df['valeur_O3_lag12'] = self.df['valeur_O3_lag12'].fillna(self.df['valeur_O3'])\n",
    "            self.df['valeur_PM10_lag12'] = self.df['valeur_PM10_lag12'].fillna(self.df['valeur_PM10'])\n",
    "            self.df['valeur_PM25_lag12'] = self.df['valeur_PM25_lag12'].fillna(self.df['valeur_PM25'])\n",
    "\n",
    "            self.df['valeur_NO2_lag24'] = self.df['valeur_NO2_lag24'].fillna(self.df['valeur_NO2'])\n",
    "            self.df['valeur_CO_lag24'] = self.df['valeur_CO_lag24'].fillna(self.df['valeur_CO'])\n",
    "            self.df['valeur_O3_lag24'] = self.df['valeur_O3_lag24'].fillna(self.df['valeur_O3'])\n",
    "            self.df['valeur_PM10_lag24'] = self.df['valeur_PM10_lag24'].fillna(self.df['valeur_PM10'])\n",
    "            self.df['valeur_PM25_lag24'] = self.df['valeur_PM25_lag24'].fillna(self.df['valeur_PM25'])\n",
    "\n",
    "            self.df.set_index(\"date\", inplace=True)\n",
    "        \n",
    "        else:\n",
    "            self.df.set_index(\"date\", inplace=True)\n",
    "\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, df, test: bool=False):\n",
    "\n",
    "        if test == False:\n",
    "            self.df = df\n",
    "            self.X = self.df.drop(['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25'], axis=1) \n",
    "            y = self.df[['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']]  \n",
    "\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, y, test_size=0.12, random_state=42, shuffle=False)\n",
    "\n",
    "            self.pipe(test=False)\n",
    "        \n",
    "        else:\n",
    "            self.df = df\n",
    "            self.pipe(test=True)\n",
    "        \n",
    "        \n",
    "    def pipe(self, test: bool=False):\n",
    "        \n",
    "        categorical_features = ['year', 'holiday', 'rush_hour', 'lockdown', 'curfew']\n",
    "\n",
    "        numerical_features = ['weekend', 'valeur_NO2_lag1', 'valeur_CO_lag1', 'valeur_O3_lag1',\n",
    "            'valeur_PM10_lag1', 'valeur_PM25_lag1', 'valeur_NO2_lag12',\n",
    "            'valeur_CO_lag12', 'valeur_O3_lag12', 'valeur_PM10_lag12',\n",
    "            'valeur_PM25_lag12', 'valeur_NO2_lag24', 'valeur_CO_lag24',\n",
    "            'valeur_O3_lag24', 'valeur_PM10_lag24', 'valeur_PM25_lag24', 'flow',\n",
    "            'occupation_rate', 'ALTI', 'RR1', 'QRR1', 'T', 'QT', 'TN', 'QTN', 'QHTN', 'TX', 'QTX',\n",
    "            'QHTX', 'DG', 'QDG']\n",
    "\n",
    "        dates = [\"weekday\", \"month\", \"hour\", 'day']\n",
    "\n",
    "        cyclical = CyclicalFeatures(variables=None, drop_original=True)\n",
    "\n",
    "        full_pipeline = ColumnTransformer([\n",
    "                (\"cat\", OneHotEncoder(sparse_output=False), categorical_features),\n",
    "                (\"num\", MinMaxScaler(), numerical_features), \n",
    "                (\"dates\", cyclical, dates),\n",
    "            ], remainder='passthrough').set_output(transform='pandas')\n",
    "        \n",
    "        if test == False:\n",
    "            self.data_train_prepared = full_pipeline.fit_transform(self.X_train)\n",
    "            self.data_test_prepared = full_pipeline.transform(self.X_test)\n",
    "\n",
    "        else:\n",
    "            self.data_pred = full_pipeline.fit_transform(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'full_pipeline' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     df_test[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvaleur_PM25_lag\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvaleur_PM25_lag\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m Preprocess(df, test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 15\u001b[0m data_test \u001b[38;5;241m=\u001b[39m \u001b[43mPreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[115], line 15\u001b[0m, in \u001b[0;36mPreprocess.__init__\u001b[1;34m(self, df, test)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[115], line 46\u001b[0m, in \u001b[0;36mPreprocess.pipe\u001b[1;34m(self, test)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_test_prepared \u001b[38;5;241m=\u001b[39m full_pipeline\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_pred \u001b[38;5;241m=\u001b[39m \u001b[43mfull_pipeline\u001b[49m\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'full_pipeline' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "eng = Eng(df, weather, traffic, holidays)\n",
    "df = eng.output(test=False)\n",
    "eng1 = Eng(final_test, weather, traffic, holidays)\n",
    "df_test = eng1.output(test=True)\n",
    "\n",
    "lags = [1, 12, 24]\n",
    "for lag in lags:\n",
    "    df_test[f'valeur_NO2_lag{lag}'] = df[f'valeur_NO2_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_CO_lag{lag}'] = df[f'valeur_CO_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_O3_lag{lag}'] = df[f'valeur_O3_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_PM10_lag{lag}'] = df[f'valeur_PM10_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_PM25_lag{lag}'] = df[f'valeur_PM25_lag{lag}'].iloc[-1]\n",
    "    \n",
    "data = Preprocess(df, test=False)\n",
    "data_test = Preprocess(df_test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_prepared  = data.data_train_prepared \n",
    "y_train = data.y_train\n",
    "\n",
    "data_test_prepared = data.data_test_prepared \n",
    "y_test = data.y_test\n",
    "\n",
    "data_pred = data_test.data_pred\n",
    "\n",
    "data_pred['cat__curfew_1'] = 0\n",
    "data_pred['cat__holiday_1'] = 0\n",
    "data_pred['cat__lockdown_1'] = 0\n",
    "data_pred['cat__year_2020'] = 0\n",
    "data_pred['cat__year_2021'] = 0\n",
    "data_pred['cat__year_2022'] = 0\n",
    "data_pred['cat__year_2023'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = MultiOutputRegressor(CatBoostRegressor(iterations=2000, l2_leaf_reg=5, \n",
    "                           learning_rate=0.15, max_depth=10, subsample=0.6, colsample_bylevel=1, \n",
    "                           verbose=False))\n",
    "\n",
    "miaou = forest.fit(data_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = miaou.predict(data_pred)\n",
    "prediction[prediction < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame(prediction, columns=[\"valeur_NO2\", \"valeur_CO\", \"valeur_O3\", \"valeur_PM10\", \"valeur_PM25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = pd.read_csv(\"../data/test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valeur_NO2</th>\n",
       "      <th>valeur_CO</th>\n",
       "      <th>valeur_O3</th>\n",
       "      <th>valeur_PM10</th>\n",
       "      <th>valeur_PM25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-09-03 23</th>\n",
       "      <td>5.618228</td>\n",
       "      <td>0.100828</td>\n",
       "      <td>16.919591</td>\n",
       "      <td>9.712663</td>\n",
       "      <td>2.413692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 00</th>\n",
       "      <td>5.567978</td>\n",
       "      <td>0.104324</td>\n",
       "      <td>16.567348</td>\n",
       "      <td>10.147752</td>\n",
       "      <td>1.149511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 01</th>\n",
       "      <td>5.748673</td>\n",
       "      <td>0.102423</td>\n",
       "      <td>18.510463</td>\n",
       "      <td>10.143395</td>\n",
       "      <td>0.818635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 02</th>\n",
       "      <td>5.430177</td>\n",
       "      <td>0.105057</td>\n",
       "      <td>14.057652</td>\n",
       "      <td>7.579638</td>\n",
       "      <td>0.537768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 03</th>\n",
       "      <td>7.309755</td>\n",
       "      <td>0.096913</td>\n",
       "      <td>13.900784</td>\n",
       "      <td>8.202288</td>\n",
       "      <td>0.837930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-24 18</th>\n",
       "      <td>11.558997</td>\n",
       "      <td>0.100852</td>\n",
       "      <td>13.324515</td>\n",
       "      <td>8.064152</td>\n",
       "      <td>2.701731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-24 19</th>\n",
       "      <td>8.242020</td>\n",
       "      <td>0.093729</td>\n",
       "      <td>15.929050</td>\n",
       "      <td>7.834085</td>\n",
       "      <td>3.075846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-24 20</th>\n",
       "      <td>8.641274</td>\n",
       "      <td>0.088829</td>\n",
       "      <td>16.702537</td>\n",
       "      <td>8.510707</td>\n",
       "      <td>2.358928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-24 21</th>\n",
       "      <td>6.409505</td>\n",
       "      <td>0.092312</td>\n",
       "      <td>14.544480</td>\n",
       "      <td>6.937440</td>\n",
       "      <td>1.810945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-24 22</th>\n",
       "      <td>4.749424</td>\n",
       "      <td>0.096838</td>\n",
       "      <td>15.021116</td>\n",
       "      <td>6.323709</td>\n",
       "      <td>2.184616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               valeur_NO2  valeur_CO  valeur_O3  valeur_PM10  valeur_PM25\n",
       "id                                                                       \n",
       "2024-09-03 23    5.618228   0.100828  16.919591     9.712663     2.413692\n",
       "2024-09-04 00    5.567978   0.104324  16.567348    10.147752     1.149511\n",
       "2024-09-04 01    5.748673   0.102423  18.510463    10.143395     0.818635\n",
       "2024-09-04 02    5.430177   0.105057  14.057652     7.579638     0.537768\n",
       "2024-09-04 03    7.309755   0.096913  13.900784     8.202288     0.837930\n",
       "...                   ...        ...        ...          ...          ...\n",
       "2024-09-24 18   11.558997   0.100852  13.324515     8.064152     2.701731\n",
       "2024-09-24 19    8.242020   0.093729  15.929050     7.834085     3.075846\n",
       "2024-09-24 20    8.641274   0.088829  16.702537     8.510707     2.358928\n",
       "2024-09-24 21    6.409505   0.092312  14.544480     6.937440     1.810945\n",
       "2024-09-24 22    4.749424   0.096838  15.021116     6.323709     2.184616\n",
       "\n",
       "[504 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.index = final_test.index\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv(\"../output/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE is 0.3778390200766095 for the train set.\n",
      "The MAE is 2.1559772487021363 for the test set.\n"
     ]
    }
   ],
   "source": [
    "prediction = miaou.predict(data_pred)\n",
    "prediction[prediction < 0] = 0\n",
    "\n",
    "print(f\"The MAE is {mean_absolute_error(miaou.predict(data_train_prepared), y_train)} for the train set.\")\n",
    "print(f\"The MAE is {mean_absolute_error(prediction, y_test)} for the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 12, 24]\n",
    "for lag in lags:\n",
    "    df_test[f'valeur_NO2_lag{lag}'] = df[f'valeur_NO2_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_CO_lag{lag}'] = df[f'valeur_CO_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_O3_lag{lag}'] = df[f'valeur_O3_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_PM10_lag{lag}'] = df[f'valeur_PM10_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_PM25_lag{lag}'] = df[f'valeur_PM25_lag{lag}'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "\n",
    "# Create sample data (same as before)\n",
    "date_rng = pd.date_range(start='2022-01-01', end='2022-01-30', freq='H')\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random target values for 5 different targets\n",
    "target_values_1 = np.random.rand(len(date_rng)) * 100\n",
    "target_values_2 = np.random.rand(len(date_rng)) * 50\n",
    "target_values_3 = np.random.rand(len(date_rng)) * 30\n",
    "target_values_4 = np.random.rand(len(date_rng)) * 200\n",
    "target_values_5 = np.random.rand(len(date_rng)) * 80\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(date_rng, columns=['date'])\n",
    "df['target_1'] = target_values_1\n",
    "df['target_2'] = target_values_2\n",
    "df['target_3'] = target_values_3\n",
    "df['target_4'] = target_values_4\n",
    "df['target_5'] = target_values_5\n",
    "\n",
    "# Prepare the predictions for each target using Prophet\n",
    "for target in ['target_1', 'target_2', 'target_3', 'target_4', 'target_5']:\n",
    "    df_prophet = df.rename(columns={'date': 'ds', target: 'y'})\n",
    "    \n",
    "    # Initialize and fit the Prophet model\n",
    "    model = Prophet()\n",
    "    model.fit(df_prophet)\n",
    "\n",
    "    # Create a DataFrame for future predictions (next 5 hours)\n",
    "    future_dates = model.make_future_dataframe(periods=5, freq='H')\n",
    "\n",
    "    # Make predictions\n",
    "    forecast = model.predict(future_dates)\n",
    "\n",
    "    # Display predictions\n",
    "    print(f\"\\nPredicted Values for {target}:\")\n",
    "    print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from darts.models import CatBoostModel\n",
    "from darts.metrics import mape\n",
    "\n",
    "# Create sample data\n",
    "date_rng = pd.date_range(start='2022-01-01', end='2022-01-30', freq='H')\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random target values for 5 different targets\n",
    "target_values_1 = np.random.rand(len(date_rng)) * 100\n",
    "target_values_2 = np.random.rand(len(date_rng)) * 50\n",
    "target_values_3 = np.random.rand(len(date_rng)) * 30\n",
    "target_values_4 = np.random.rand(len(date_rng)) * 200\n",
    "target_values_5 = np.random.rand(len(date_rng)) * 80\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(date_rng, columns=['date'])\n",
    "df['target_1'] = target_values_1\n",
    "df['target_2'] = target_values_2\n",
    "df['target_3'] = target_values_3\n",
    "df['target_4'] = target_values_4\n",
    "df['target_5'] = target_values_5\n",
    "\n",
    "# Convert to Darts TimeSeries for each target\n",
    "series_1 = TimeSeries.from_dataframe(df, 'date', 'target_1')\n",
    "series_2 = TimeSeries.from_dataframe(df, 'date', 'target_2')\n",
    "series_3 = TimeSeries.from_dataframe(df, 'date', 'target_3')\n",
    "series_4 = TimeSeries.from_dataframe(df, 'date', 'target_4')\n",
    "series_5 = TimeSeries.from_dataframe(df, 'date', 'target_5')\n",
    "\n",
    "# Train-test split for each series\n",
    "train_1, test_1 = series_1.split_after(0.8)\n",
    "train_2, test_2 = series_2.split_after(0.8)\n",
    "train_3, test_3 = series_3.split_after(0.8)\n",
    "train_4, test_4 = series_4.split_after(0.8)\n",
    "train_5, test_5 = series_5.split_after(0.8)\n",
    "\n",
    "# Initialize CatBoost model for each target\n",
    "model_1 = CatBoostModel()\n",
    "model_2 = CatBoostModel()\n",
    "model_3 = CatBoostModel()\n",
    "model_4 = CatBoostModel()\n",
    "model_5 = CatBoostModel()\n",
    "\n",
    "# Fit the model for each target\n",
    "model_1.fit(train_1)\n",
    "model_2.fit(train_2)\n",
    "model_3.fit(train_3)\n",
    "model_4.fit(train_4)\n",
    "model_5.fit(train_5)\n",
    "\n",
    "# Perform recursive forecasting for each target\n",
    "predictions_1 = model_1.predict(len(test_1))\n",
    "predictions_2 = model_2.predict(len(test_2))\n",
    "predictions_3 = model_3.predict(len(test_3))\n",
    "predictions_4 = model_4.predict(len(test_4))\n",
    "predictions_5 = model_5.predict(len(test_5))\n",
    "\n",
    "# Display predictions\n",
    "print(\"\\nPredicted Values for Target 1:\")\n",
    "print(predictions_1.values())\n",
    "\n",
    "print(\"\\nPredicted Values for Target 2:\")\n",
    "print(predictions_2.values())\n",
    "\n",
    "print(\"\\nPredicted Values for Target 3:\")\n",
    "print(predictions_3.values())\n",
    "\n",
    "print(\"\\nPredicted Values for Target 4:\")\n",
    "print(predictions_4.values())\n",
    "\n",
    "print(\"\\nPredicted Values for Target 5:\")\n",
    "print(predictions_5.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air_quality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
