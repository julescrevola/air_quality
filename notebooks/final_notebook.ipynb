{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import BayesianRidge, HuberRegressor, PassiveAggressiveRegressor, TheilSenRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "path = \"../data/train.csv\"\n",
    "df = pd.read_csv(path, parse_dates=[0])\n",
    "\n",
    "df_weather1 = pd.read_csv(\"https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/HOR/H_75_previous-2020-2022.csv.gz\", sep=';')\n",
    "df_weather2 = pd.read_csv(\"https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/HOR/H_75_latest-2023-2024.csv.gz\", sep=';')\n",
    "weather = pd.concat([df_weather1, df_weather2])\n",
    "\n",
    "holidays_path = \"../data/fr-en-calendrier-scolaire.csv\"\n",
    "holidays = pd.read_csv(holidays_path, sep=\";\")\n",
    "\n",
    "traffic_path = \"../data/traffic_data.csv\"\n",
    "traffic = pd.read_csv(traffic_path, sep=\";\")\n",
    "\n",
    "final_test = pd.read_csv(\"../data/test.csv\", parse_dates=[0]).rename(columns={\"id\": \"date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eng:\n",
    "    def __init__(self, df, weather, traffic, holidays):\n",
    "        self.df = df\n",
    "        self.df = self.df.rename(columns={\"id\": \"date\"})\n",
    "        self.df = self.df.drop_duplicates()\n",
    "\n",
    "        self.external_database(weather, traffic)\n",
    "        self.additional_data(holidays)\n",
    "        self.date_features()\n",
    "        \n",
    "\n",
    "    def external_database(self, weather, traffic):\n",
    "        \n",
    "        ##### Weather #####\n",
    "        \n",
    "        self.weather = weather\n",
    "\n",
    "        # Dropping empty columns\n",
    "        self.weather = self.weather.drop(\n",
    "            columns=['FF2', 'QFF2', 'DD2', 'QDD2', 'FXI2', 'QFXI2', 'DXI2', 'QDXI2', 'HXI2', 'QHXI2', 'DXI3S',\n",
    "                                      'DHUMEC', 'QDHUMEC', 'GEOP', 'QGEOP', 'N', 'QN', 'NBAS', 'QNBAS', 'CL', 'QCL', 'CM', 'QCM',\n",
    "                                      'CH', 'QCH', 'N1', 'QN1', 'C1', 'QC1', 'B1', 'QB1', 'N2', 'QN2', 'C2', 'QC2', 'B2', 'QB2',\n",
    "                                      'N3', 'QN3', 'C3', 'QC3', 'B3', 'QB3', 'N4', 'QN4', 'C4', 'QC4', 'B4', 'QB4', 'W1', 'QW1',\n",
    "                                      'W2', 'QW2', 'SOL', 'QSOL', 'SOLNG', 'QSOLNG', 'TMER', 'QTMER', 'VVMER', 'QVVMER', 'ETATMER',\n",
    "                                      'QETATMER', 'DIRHOULE', 'QDIRHOULE', 'HVAGUE', 'QHVAGUE', 'PVAGUE', 'QPVAGUE', 'HNEIGEF', 'QHNEIGEF',\n",
    "                                      'TSNEIGE', 'QTSNEIGE', 'TUBENEIGE', 'QTUBENEIGE', 'HNEIGEFI3', 'QHNEIGEFI3', 'HNEIGEFI1', 'QHNEIGEFI1',\n",
    "                                      'ESNEIGE', 'QESNEIGE', 'CHARGENEIGE', 'QCHARGENEIGE', 'DIR', 'QDIR', 'DIR2', 'QDIR2', 'DIF', 'QDIF',\n",
    "                                      'DIF2', 'QDIF2', 'UV', 'QUV', 'UV2', 'QUV2', 'UV_INDICE', 'QUV_INDICE', 'INFRAR', 'QINFRAR', 'INFRAR2',\n",
    "                                      'QINFRAR2', 'TLAGON', 'QTLAGON', 'TVEGETAUX', 'QTVEGETAUX', 'ECOULEMENT', 'QECOULEMENT', 'NUM_POSTE',\n",
    "                                      'NOM_USUEL', 'LAT', 'LON', 'DRR1', 'FF', 'QFF', 'DD', 'QDD', 'FXY', 'QFXY', 'DXY', 'QDXY', 'QHXY', 'FXI',\n",
    "                                      'QFXI', 'DXI', 'QDXI', 'QHXI', 'FXI3S', 'QFXI3S', 'QDXI3S', 'QHFXI3S', 'TD', 'QTD', 'T10', 'QT10', 'T20',\n",
    "                                      'QT20', 'T50', 'QT50', 'T100', 'QT100', 'TNSOL', 'QTNSOL', 'TN50', 'QTN50', 'TCHAUSSEE', 'QTCHAUSSEE',\n",
    "                                      'U', 'QU', 'UN', 'QUN', 'QHUN', 'UX', 'QUX', 'QHUX', 'DHUMI40', 'QDHUMI40', 'DHUMI80', 'QDHUMI80', 'TSV',\n",
    "                                      'QTSV', 'PMER', 'QPMER', 'PSTAT', 'QPSTAT', 'PMERMIN', 'QPMERMIN', 'VV', 'QVV', 'DVV200', 'QDVV200', 'WW',\n",
    "                                      'QWW', 'NEIGETOT', 'QNEIGETOT', 'GLO', 'QGLO', 'GLO2', 'QGLO2', 'INS', 'QINS', 'INS2', 'QINS2', 'QDRR1']\n",
    "                                      )\n",
    "        \n",
    "        # Grouping by date to sum and average values across all meteo stations\n",
    "        self.weather[\"date\"] = pd.to_datetime(self.weather[\"AAAAMMJJHH\"], format=\"%Y%m%d%H\")\n",
    "        self.weather = self.weather.drop(columns=[\"AAAAMMJJHH\", \"HXI\", \"HXY\", \"HFXI3S\", \"HTN\", \"HTX\", \"HUN\", \"HUX\"])\n",
    "\n",
    "        self.avg = self.weather.drop(\n",
    "            columns=['RR1']\n",
    "            ).groupby(\"date\").mean().reset_index()\n",
    "\n",
    "        self.tot = self.weather.drop(\n",
    "            columns=['TX', 'T', 'QTX', 'DG', 'QT', 'QHTN', 'QHTX', 'TN', 'QDG', 'QTN']\n",
    "            ).groupby(\"date\").sum().reset_index()\n",
    "\n",
    "        self.weather = self.weather.drop_duplicates(subset=[\"date\"])\n",
    "\n",
    "        self.df = self.df.merge(self.weather, on=\"date\", how=\"left\")\n",
    "\n",
    "        # Filling missing values for weather data with their mean as there are very few\n",
    "        self.is_na = self.df.isna().sum()\n",
    "\n",
    "        for col in self.is_na.index:\n",
    "            if self.is_na[col] > 0:\n",
    "                self.df[col] = self.df[col].fillna(self.df[col].mean())\n",
    "        \n",
    "\n",
    "        ##### Traffic #####\n",
    "        \n",
    "        # traffic.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "        traffic[\"date\"] = pd.to_datetime(traffic[\"date\"])\n",
    "\n",
    "        traffic = traffic.drop_duplicates(subset=[\"date\"])\n",
    "        linear_int2 = traffic[[\"date\", 'flow', 'occupation_rate']]\n",
    "        linear_int2 = linear_int2.set_index(\"date\")\n",
    "        new_features2 = linear_int2.resample('1h').interpolate(\"linear\")\n",
    "\n",
    "        self.df = self.df.merge(new_features2, on=\"date\", how=\"left\")\n",
    "\n",
    "        self.df[\"flow\"] = self.df[\"flow\"].fillna(self.df[\"flow\"].mean())\n",
    "        self.df[\"occupation_rate\"] = self.df[\"occupation_rate\"].fillna(self.df[\"occupation_rate\"].mean())\n",
    "        \n",
    "\n",
    "    def date_features(self):\n",
    "        # Create new date features\n",
    "        self.df['day'] = self.df['date'].dt.day\n",
    "        self.df['month'] = self.df['date'].dt.month\n",
    "        self.df['year'] = self.df['date'].dt.year\n",
    "        self.df['hour'] = self.df['date'].dt.hour\n",
    "        self.df['weekday'] = self.df['date'].dt.weekday \n",
    "        \n",
    "        self.df[\"weekend\"] = self.df['weekday'].isin([5, 6])\n",
    "        \n",
    "\n",
    "    def additional_data(self, holidays):\n",
    "    \n",
    "        ###### Lockdown variable ######\n",
    "        \n",
    "        # Lockdown in Paris\n",
    "        start_date = pd.to_datetime('2020-10-31')\n",
    "        end_date = pd.to_datetime('2020-12-14')\n",
    "        start_date1 = pd.to_datetime('2021-04-04')\n",
    "        end_date1 = pd.to_datetime('2021-05-02')\n",
    "        \n",
    "        # Assign 1 if the date is within the specified range, otherwise 0\n",
    "        self.df['lockdown'] = self.df['date'].apply(lambda x: 1 if ((start_date <= x <= end_date) or (start_date1 <= x <= end_date1)) else 0)\n",
    "        \n",
    "\n",
    "        ###### Curfews variable ######\n",
    "        \n",
    "        # Curfew date range (+1 hour because the data is the cumulative of the previous)\n",
    "        curfew_periods = [\n",
    "            (pd.to_datetime('2020-10-17 22:00'), pd.to_datetime('2020-10-29 07:00')),\n",
    "            (pd.to_datetime('2020-12-16 21:00'), pd.to_datetime('2021-01-15 07:00')),\n",
    "            (pd.to_datetime('2021-01-16 19:00'), pd.to_datetime('2021-03-20 07:00')),\n",
    "            (pd.to_datetime('2021-03-21 20:00'), pd.to_datetime('2021-04-02 07:00')),\n",
    "            (pd.to_datetime('2021-05-19 22:00'), pd.to_datetime('2021-06-08 07:00')),\n",
    "            (pd.to_datetime('2021-06-09 23:00'), pd.to_datetime('2021-06-20 07:00'))\n",
    "        ]\n",
    "\n",
    "        # Create a new column 'Curfew' and assign 1 if the date is within the specified range, otherwise 0\n",
    "\n",
    "        self.df['curfew'] = 0  # Initialize the Curfew column\n",
    "\n",
    "        # Loop through curfew periods and set Curfew column accordingly\n",
    "        for start_time, end_time in curfew_periods:\n",
    "            mask = self.df[self.df['date'].between(start_time, end_time)]\n",
    "            mask = mask[(mask[\"date\"].dt.hour > start_time.hour) | (mask[\"date\"].dt.hour < end_time.hour)]\n",
    "            self.df.loc[mask.index, 'curfew'] = 1\n",
    "            \n",
    "        \n",
    "        ###### Holidays variable ######\n",
    "\n",
    "        # Consider only metropolitan areas\n",
    "        holidays = holidays[holidays[\"Zones\"].isin([\"Zone C\"])]\n",
    "\n",
    "        # Consider only relevant years\n",
    "        holidays = holidays[holidays[\"annee_scolaire\"].isin([\"2020-2021\", \"2021-2022\"])]\n",
    "\n",
    "        # Distinguish for holidays in Paris or not\n",
    "        holidays['Holidays in Paris'] = 1\n",
    "\n",
    "        holidays.drop([\"Académies\",\"Population\", \"Zones\"], axis=1, inplace = True)\n",
    "\n",
    "        # Convert to same date format\n",
    "        holidays['Date de début'] = holidays['Date de début'].apply(lambda x: x[0:10]+' '+x[11:19])\n",
    "        holidays['Date de fin'] = holidays['Date de fin'].apply(lambda x: x[0:10]+' '+x[11:19])\n",
    "\n",
    "        holidays[\"Date de début\"] = pd.to_datetime(holidays[\"Date de début\"], format='%Y-%m-%d %H:%M:%S')\n",
    "        holidays[\"Date de fin\"] = pd.to_datetime(holidays[\"Date de fin\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Remove holidays starting after final date of dataset\n",
    "        holidays = holidays[holidays[\"Date de début\"].dt.year != 2022]\n",
    "\n",
    "        # Remove summer holidays\n",
    "        holidays = holidays[holidays[\"Description\"] != \"Vacances d'Été\"]\n",
    "        holidays.drop([\"Description\",\"annee_scolaire\"], axis=1, inplace=True)\n",
    "\n",
    "        # Drop same holidays\n",
    "        holidays = holidays.drop_duplicates(subset=['Date de début', 'Date de fin'], keep='first')\n",
    "\n",
    "        # Create holidays date ranges \n",
    "        ranges = []\n",
    "        for x in holidays[[\"Date de début\",\"Date de fin\"]].values:\n",
    "            ranges.append(pd.date_range(x[0], x[1], freq=\"h\"))\n",
    "            \n",
    "            \n",
    "        def is_date_within_ranges(date, ranges):\n",
    "            for date_range in ranges:\n",
    "                if date_range[0] <= date <= date_range[-1]:\n",
    "                    return 1\n",
    "            return 0\n",
    "\n",
    "        # Apply the function to create a new column indicating whether the date is within any holiday range\n",
    "        self.df['holiday'] = self.df['date'].apply(lambda x: is_date_within_ranges(x, ranges))\n",
    "        \n",
    "        \n",
    "        ###### Rush hour ########\n",
    "        def is_rush_hour(x):\n",
    "            if ((7 <= x.hour <= 9) or (16 <= x.hour <= 19)) and x.weekday != 5 and x.weekday != 6:\n",
    "                return 1\n",
    "            elif (x.weekday == 5 or x.weekday == 6) and (16 <= x.hour <= 19):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "        self.df['rush_hour'] = self.df['date'].apply(lambda x: is_rush_hour(x))\n",
    "        \n",
    "\n",
    "    def output(self, test: bool):\n",
    "\n",
    "        if test == False:\n",
    "\n",
    "            # Using interpolation to fill in missing values before adding lag features\n",
    "            linear_int = self.df[[\"date\", \"valeur_NO2\", \"valeur_CO\", \"valeur_O3\", \"valeur_PM10\", \"valeur_PM25\"]]\n",
    "            linear_int = linear_int.set_index(\"date\")\n",
    "            new_features = linear_int.resample('1h').interpolate(\"linear\")\n",
    "\n",
    "            self.df = self.df.merge(new_features, on=\"date\", how=\"left\")\n",
    "            self.df = self.df.rename(columns={'valeur_NO2_y': 'valeur_NO2', 'valeur_CO_y': 'valeur_CO', 'valeur_O3_y': 'valeur_O3', 'valeur_PM10_y': 'valeur_PM10',\n",
    "                'valeur_PM25_y': 'valeur_PM25'})\n",
    "            self.df = self.df.drop(['valeur_NO2_x', 'valeur_CO_x', 'valeur_O3_x', 'valeur_PM10_x',\n",
    "                'valeur_PM25_x'], axis=1)\n",
    "            \n",
    "            # Generating lag columns\n",
    "            self.df[\"valeur_NO2_lag1\"] = self.df['valeur_NO2'].shift(1)\n",
    "            self.df[\"valeur_CO_lag1\"] = self.df['valeur_CO'].shift(1)\n",
    "            self.df[\"valeur_O3_lag1\"] = self.df['valeur_O3'].shift(1)\n",
    "            self.df[\"valeur_PM10_lag1\"] = self.df['valeur_PM10'].shift(1)\n",
    "            self.df[\"valeur_PM25_lag1\"] = self.df['valeur_PM25'].shift(1)\n",
    "\n",
    "            self.df[\"valeur_NO2_lag12\"] = self.df['valeur_NO2'].shift(12)\n",
    "            self.df[\"valeur_CO_lag12\"] = self.df['valeur_CO'].shift(12)\n",
    "            self.df[\"valeur_O3_lag12\"] = self.df['valeur_O3'].shift(12)\n",
    "            self.df[\"valeur_PM10_lag12\"] = self.df['valeur_PM10'].shift(12)\n",
    "            self.df[\"valeur_PM25_lag12\"] = self.df['valeur_PM25'].shift(12)\n",
    "\n",
    "            self.df[\"valeur_NO2_lag24\"] = self.df['valeur_NO2'].shift(24)\n",
    "            self.df[\"valeur_CO_lag24\"] = self.df['valeur_CO'].shift(24)\n",
    "            self.df[\"valeur_O3_lag24\"] = self.df['valeur_O3'].shift(24)\n",
    "            self.df[\"valeur_PM10_lag24\"] = self.df['valeur_PM10'].shift(24)\n",
    "            self.df[\"valeur_PM25_lag24\"] = self.df['valeur_PM25'].shift(24)\n",
    "\n",
    "            # Filling NaNs\n",
    "            self.df['valeur_NO2_lag1'] = self.df['valeur_NO2_lag1'].fillna(self.df['valeur_NO2'])\n",
    "            self.df['valeur_CO_lag1'] = self.df['valeur_CO_lag1'].fillna(self.df['valeur_CO'])\n",
    "            self.df['valeur_O3_lag1'] = self.df['valeur_O3_lag1'].fillna(self.df['valeur_O3'])\n",
    "            self.df['valeur_PM10_lag1'] = self.df['valeur_PM10_lag1'].fillna(self.df['valeur_PM10'])\n",
    "            self.df['valeur_PM25_lag1'] = self.df['valeur_PM25_lag1'].fillna(self.df['valeur_PM25'])\n",
    "\n",
    "            self.df['valeur_NO2_lag12'] = self.df['valeur_NO2_lag12'].fillna(self.df['valeur_NO2'])\n",
    "            self.df['valeur_CO_lag12'] = self.df['valeur_CO_lag12'].fillna(self.df['valeur_CO'])\n",
    "            self.df['valeur_O3_lag12'] = self.df['valeur_O3_lag12'].fillna(self.df['valeur_O3'])\n",
    "            self.df['valeur_PM10_lag12'] = self.df['valeur_PM10_lag12'].fillna(self.df['valeur_PM10'])\n",
    "            self.df['valeur_PM25_lag12'] = self.df['valeur_PM25_lag12'].fillna(self.df['valeur_PM25'])\n",
    "\n",
    "            self.df['valeur_NO2_lag24'] = self.df['valeur_NO2_lag24'].fillna(self.df['valeur_NO2'])\n",
    "            self.df['valeur_CO_lag24'] = self.df['valeur_CO_lag24'].fillna(self.df['valeur_CO'])\n",
    "            self.df['valeur_O3_lag24'] = self.df['valeur_O3_lag24'].fillna(self.df['valeur_O3'])\n",
    "            self.df['valeur_PM10_lag24'] = self.df['valeur_PM10_lag24'].fillna(self.df['valeur_PM10'])\n",
    "            self.df['valeur_PM25_lag24'] = self.df['valeur_PM25_lag24'].fillna(self.df['valeur_PM25'])\n",
    "\n",
    "            self.df.set_index(\"date\", inplace=True)\n",
    "        \n",
    "        else:\n",
    "            self.df.set_index(\"date\", inplace=True)\n",
    "\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        self.X = self.df.drop(['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25'], axis=1) \n",
    "        y = self.df[['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']]  \n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, y, test_size=0.12, random_state=42, shuffle=False)\n",
    "        \n",
    "        # Test dataset\n",
    "        self.test_df = final_test\n",
    "        \n",
    "        self.pipe()\n",
    "        \n",
    "        \n",
    "    def pipe(self):\n",
    "        \n",
    "        categorical_features = ['year', 'holiday', 'rush_hour', 'lockdown', 'curfew']\n",
    "\n",
    "        numerical_features = ['weekend', 'valeur_NO2_lag1', 'valeur_CO_lag1', 'valeur_O3_lag1',\n",
    "            'valeur_PM10_lag1', 'valeur_PM25_lag1', 'valeur_NO2_lag12',\n",
    "            'valeur_CO_lag12', 'valeur_O3_lag12', 'valeur_PM10_lag12',\n",
    "            'valeur_PM25_lag12', 'valeur_NO2_lag24', 'valeur_CO_lag24',\n",
    "            'valeur_O3_lag24', 'valeur_PM10_lag24', 'valeur_PM25_lag24', 'flow',\n",
    "            'occupation_rate', 'ALTI', 'RR1', 'QRR1', 'T', 'QT', 'TN', 'QTN', 'QHTN', 'TX', 'QTX',\n",
    "            'QHTX', 'DG', 'QDG']\n",
    "\n",
    "        dates = [\"weekday\", \"month\", \"hour\", 'day']\n",
    "\n",
    "        cyclical = CyclicalFeatures(variables=None, drop_original=True)\n",
    "\n",
    "        full_pipeline = ColumnTransformer([\n",
    "                (\"cat\", OneHotEncoder(sparse_output=False), categorical_features),\n",
    "                (\"num\", MinMaxScaler(), numerical_features), \n",
    "                (\"dates\", cyclical, dates),\n",
    "            ], remainder='passthrough').set_output(transform='pandas')\n",
    "\n",
    "        self.data_train_prepared = full_pipeline.fit_transform(self.X_train)\n",
    "        self.data_test_prepared = full_pipeline.transform(self.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = Eng(df, weather, traffic, holidays)\n",
    "df = eng.output(test=False)\n",
    "eng1 = Eng(final_test, weather, traffic, holidays)\n",
    "df_test = eng1.output(test=True)\n",
    "data = Preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_prepared  = data.data_train_prepared \n",
    "y_train = data.y_train\n",
    "\n",
    "data_test_prepared = data.data_test_prepared \n",
    "y_test = data.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = MultiOutputRegressor(CatBoostRegressor(iterations=2000, l2_leaf_reg=5, \n",
    "                           learning_rate=0.15, max_depth=10, subsample=0.6, colsample_bylevel=1, \n",
    "                           verbose=False))\n",
    "\n",
    "miaou = forest.fit(data_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE is 0.3778390200766095 for the train set.\n",
      "The MAE is 2.1559772487021363 for the test set.\n"
     ]
    }
   ],
   "source": [
    "prediction = miaou.predict(data_test_prepared)\n",
    "prediction[prediction < 0] = 0\n",
    "\n",
    "print(f\"The MAE is {mean_absolute_error(miaou.predict(data_train_prepared), y_train)} for the train set.\")\n",
    "print(f\"The MAE is {mean_absolute_error(prediction, y_test)} for the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 12, 24]\n",
    "for lag in lags:\n",
    "    df_test[f'valeur_NO2_lag{lag}'] = df[f'valeur_NO2_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_CO_lag{lag}'] = df[f'valeur_CO_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_O3_lag{lag}'] = df[f'valeur_O3_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_PM10_lag{lag}'] = df[f'valeur_PM10_lag{lag}'].iloc[-1]\n",
    "    df_test[f'valeur_PM25_lag{lag}'] = df[f'valeur_PM25_lag{lag}'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALTI</th>\n",
       "      <th>RR1</th>\n",
       "      <th>QRR1</th>\n",
       "      <th>T</th>\n",
       "      <th>QT</th>\n",
       "      <th>TN</th>\n",
       "      <th>QTN</th>\n",
       "      <th>QHTN</th>\n",
       "      <th>TX</th>\n",
       "      <th>QTX</th>\n",
       "      <th>...</th>\n",
       "      <th>valeur_NO2_lag12</th>\n",
       "      <th>valeur_CO_lag12</th>\n",
       "      <th>valeur_O3_lag12</th>\n",
       "      <th>valeur_PM10_lag12</th>\n",
       "      <th>valeur_PM25_lag12</th>\n",
       "      <th>valeur_NO2_lag24</th>\n",
       "      <th>valeur_CO_lag24</th>\n",
       "      <th>valeur_O3_lag24</th>\n",
       "      <th>valeur_PM10_lag24</th>\n",
       "      <th>valeur_PM25_lag24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-09-03 23:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.182</td>\n",
       "      <td>49.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.162</td>\n",
       "      <td>56.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 00:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.182</td>\n",
       "      <td>49.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.162</td>\n",
       "      <td>56.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 01:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.182</td>\n",
       "      <td>49.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.162</td>\n",
       "      <td>56.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 02:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.182</td>\n",
       "      <td>49.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.162</td>\n",
       "      <td>56.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-04 03:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.182</td>\n",
       "      <td>49.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.162</td>\n",
       "      <td>56.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-24 18:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.182</td>\n",
       "      <td>49.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.162</td>\n",
       "      <td>56.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-24 19:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.182</td>\n",
       "      <td>49.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.162</td>\n",
       "      <td>56.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-24 20:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.182</td>\n",
       "      <td>49.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.162</td>\n",
       "      <td>56.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-24 21:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.182</td>\n",
       "      <td>49.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.162</td>\n",
       "      <td>56.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-24 22:00:00</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.182</td>\n",
       "      <td>49.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>21.831528</td>\n",
       "      <td>0.162</td>\n",
       "      <td>56.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ALTI  RR1  QRR1     T   QT    TN  QTN  QHTN    TX  QTX  \\\n",
       "date                                                                          \n",
       "2024-09-03 23:00:00    46  0.0   1.0  19.1  1.0  19.0  1.0   9.0  19.2  1.0   \n",
       "2024-09-04 00:00:00    46  0.0   1.0  19.0  1.0  18.9  1.0   9.0  19.1  1.0   \n",
       "2024-09-04 01:00:00    46  0.0   1.0  18.7  1.0  18.7  1.0   9.0  18.9  1.0   \n",
       "2024-09-04 02:00:00    46  0.0   1.0  18.3  1.0  18.3  1.0   9.0  18.7  1.0   \n",
       "2024-09-04 03:00:00    46  0.0   1.0  18.1  1.0  18.1  1.0   9.0  18.3  1.0   \n",
       "...                   ...  ...   ...   ...  ...   ...  ...   ...   ...  ...   \n",
       "2024-09-24 18:00:00    46  1.6   1.0  15.2  1.0  15.2  1.0   9.0  15.9  1.0   \n",
       "2024-09-24 19:00:00    46  0.0   1.0  15.2  1.0  15.1  1.0   9.0  15.2  1.0   \n",
       "2024-09-24 20:00:00    46  0.0   1.0  15.2  9.0  15.1  9.0   9.0  15.2  9.0   \n",
       "2024-09-24 21:00:00    46  0.0   1.0  14.9  1.0  14.9  1.0   9.0  15.2  1.0   \n",
       "2024-09-24 22:00:00    46  0.0   1.0  14.7  1.0  14.7  1.0   9.0  14.9  1.0   \n",
       "\n",
       "                     ...  valeur_NO2_lag12  valeur_CO_lag12  valeur_O3_lag12  \\\n",
       "date                 ...                                                       \n",
       "2024-09-03 23:00:00  ...         21.831528            0.182             49.2   \n",
       "2024-09-04 00:00:00  ...         21.831528            0.182             49.2   \n",
       "2024-09-04 01:00:00  ...         21.831528            0.182             49.2   \n",
       "2024-09-04 02:00:00  ...         21.831528            0.182             49.2   \n",
       "2024-09-04 03:00:00  ...         21.831528            0.182             49.2   \n",
       "...                  ...               ...              ...              ...   \n",
       "2024-09-24 18:00:00  ...         21.831528            0.182             49.2   \n",
       "2024-09-24 19:00:00  ...         21.831528            0.182             49.2   \n",
       "2024-09-24 20:00:00  ...         21.831528            0.182             49.2   \n",
       "2024-09-24 21:00:00  ...         21.831528            0.182             49.2   \n",
       "2024-09-24 22:00:00  ...         21.831528            0.182             49.2   \n",
       "\n",
       "                     valeur_PM10_lag12  valeur_PM25_lag12  valeur_NO2_lag24  \\\n",
       "date                                                                          \n",
       "2024-09-03 23:00:00                7.1                3.1         21.831528   \n",
       "2024-09-04 00:00:00                7.1                3.1         21.831528   \n",
       "2024-09-04 01:00:00                7.1                3.1         21.831528   \n",
       "2024-09-04 02:00:00                7.1                3.1         21.831528   \n",
       "2024-09-04 03:00:00                7.1                3.1         21.831528   \n",
       "...                                ...                ...               ...   \n",
       "2024-09-24 18:00:00                7.1                3.1         21.831528   \n",
       "2024-09-24 19:00:00                7.1                3.1         21.831528   \n",
       "2024-09-24 20:00:00                7.1                3.1         21.831528   \n",
       "2024-09-24 21:00:00                7.1                3.1         21.831528   \n",
       "2024-09-24 22:00:00                7.1                3.1         21.831528   \n",
       "\n",
       "                     valeur_CO_lag24  valeur_O3_lag24  valeur_PM10_lag24  \\\n",
       "date                                                                       \n",
       "2024-09-03 23:00:00            0.162             56.7               11.6   \n",
       "2024-09-04 00:00:00            0.162             56.7               11.6   \n",
       "2024-09-04 01:00:00            0.162             56.7               11.6   \n",
       "2024-09-04 02:00:00            0.162             56.7               11.6   \n",
       "2024-09-04 03:00:00            0.162             56.7               11.6   \n",
       "...                              ...              ...                ...   \n",
       "2024-09-24 18:00:00            0.162             56.7               11.6   \n",
       "2024-09-24 19:00:00            0.162             56.7               11.6   \n",
       "2024-09-24 20:00:00            0.162             56.7               11.6   \n",
       "2024-09-24 21:00:00            0.162             56.7               11.6   \n",
       "2024-09-24 22:00:00            0.162             56.7               11.6   \n",
       "\n",
       "                     valeur_PM25_lag24  \n",
       "date                                    \n",
       "2024-09-03 23:00:00                6.7  \n",
       "2024-09-04 00:00:00                6.7  \n",
       "2024-09-04 01:00:00                6.7  \n",
       "2024-09-04 02:00:00                6.7  \n",
       "2024-09-04 03:00:00                6.7  \n",
       "...                                ...  \n",
       "2024-09-24 18:00:00                6.7  \n",
       "2024-09-24 19:00:00                6.7  \n",
       "2024-09-24 20:00:00                6.7  \n",
       "2024-09-24 21:00:00                6.7  \n",
       "2024-09-24 22:00:00                6.7  \n",
       "\n",
       "[504 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air_quality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
