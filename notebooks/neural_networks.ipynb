{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_prepared = pd.read_csv(\"../processed_data/data_train_prepared.csv\")\n",
    "y_train = pd.read_csv(\"../processed_data/y_train.csv\")\n",
    "data_test_prepared = pd.read_csv(\"../processed_data/data_test_prepared.csv\")\n",
    "y_test = pd.read_csv(\"../processed_data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_train, num_features_train = data_train_prepared.shape\n",
    "num_samples_test, num_features_test = data_test_prepared.shape\n",
    "timesteps = 300\n",
    "\n",
    "num_sequences_train = num_samples_train // timesteps\n",
    "num_sequences_test = num_samples_test // timesteps\n",
    "\n",
    "# Reshape data to 3D: (num_sequences, timesteps, num_features) to use LSTM layer\n",
    "data_train_3D = data_train_prepared.values[:num_sequences_train * timesteps].reshape((num_sequences_train, timesteps, num_features_train))\n",
    "data_test_3D = data_test_prepared.values[:num_sequences_test * timesteps].reshape((num_sequences_test, timesteps, num_features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 300, 256)         187392    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300, 256)          0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 352,389\n",
      "Trainable params: 352,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 1096.3049 - mae: 19.4397 - val_loss: 754.0792 - val_mae: 15.6424\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 687.9742 - mae: 16.6423 - val_loss: 993.6059 - val_mae: 14.5279\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 920.4885 - mae: 15.8819 - val_loss: 382.6308 - val_mae: 13.3155\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 380.0088 - mae: 14.9196 - val_loss: 630.6124 - val_mae: 13.0645\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 579.6314 - mae: 14.4077 - val_loss: 299.0902 - val_mae: 12.6675\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 1s 583ms/step - loss: 288.2116 - mae: 14.2032 - val_loss: 494.6443 - val_mae: 12.5511\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 1s 578ms/step - loss: 471.7353 - mae: 13.7440 - val_loss: 283.8953 - val_mae: 12.3899\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 1s 595ms/step - loss: 250.2946 - mae: 13.7474 - val_loss: 395.3830 - val_mae: 13.0609\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 1s 616ms/step - loss: 390.1750 - mae: 14.2472 - val_loss: 207.9433 - val_mae: 13.5224\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 1s 724ms/step - loss: 238.1877 - mae: 14.9835 - val_loss: 376.5961 - val_mae: 13.7204\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 1s 712ms/step - loss: 369.9486 - mae: 14.5027 - val_loss: 182.3872 - val_mae: 12.5550\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 1s 720ms/step - loss: 221.0746 - mae: 13.8711 - val_loss: 294.7670 - val_mae: 12.4786\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 1s 717ms/step - loss: 292.0293 - mae: 13.5509 - val_loss: 48.7564 - val_mae: 12.1514\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 1s 716ms/step - loss: 216.2986 - mae: 14.0577 - val_loss: 256.6526 - val_mae: 13.1671\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 1s 750ms/step - loss: 213.4680 - mae: 14.2283 - val_loss: 203.7288 - val_mae: 12.9162\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 1s 733ms/step - loss: 240.6366 - mae: 14.4489 - val_loss: 109.2956 - val_mae: 12.0572\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 1s 791ms/step - loss: 180.7691 - mae: 13.1640 - val_loss: 280.3062 - val_mae: 12.0166\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 2s 759ms/step - loss: 228.2840 - mae: 12.9861 - val_loss: 196.0114 - val_mae: 11.7974\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 1s 730ms/step - loss: 221.4124 - mae: 13.0765 - val_loss: 125.3571 - val_mae: 11.6472\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 1s 696ms/step - loss: 174.7187 - mae: 13.3104 - val_loss: 306.9609 - val_mae: 11.8459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26be7f35270>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using LSTM ### \n",
    "\n",
    "# Define the model\n",
    "model_lstm = keras.Sequential()\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model_lstm.add(layers.Bidirectional(layers.LSTM(128, return_sequences=True), input_shape=(timesteps, num_features_train)))\n",
    "model_lstm.add(layers.Dropout(0.5))\n",
    "\n",
    "# Add another LSTM layer\n",
    "model_lstm.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "model_lstm.add(layers.Dropout(0.5))\n",
    "\n",
    "# Add a Dense layer with 5 units.\n",
    "model_lstm.add(layers.Dense(y_train.shape[1]))\n",
    "\n",
    "# Display the model summary\n",
    "print(model_lstm.summary())\n",
    "\n",
    "# Training the model\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss=keras.losses.MeanAbsolutePercentageError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.3),\n",
    "    metrics=[\"mae\"],\n",
    ")\n",
    "\n",
    "\n",
    "model_lstm.fit(\n",
    "    data_train_3D,\n",
    "    y_train[:num_sequences_train],\n",
    "    validation_data=(data_test_3D, y_test[:num_sequences_test]),\n",
    "    batch_size=batch_size,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 128)               70656     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,301\n",
      "Trainable params: 71,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 601ms/step - loss: 475.3690 - mae: 21.8109 - val_loss: 392.8328 - val_mae: 21.7347\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 448.6837 - mae: 23.6634 - val_loss: 158.2043 - val_mae: 19.5522\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 269.0230 - mae: 19.4268 - val_loss: 132.2361 - val_mae: 12.1501\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 267.2158 - mae: 13.3113 - val_loss: 350.9430 - val_mae: 10.9653\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 298.9384 - mae: 12.0806 - val_loss: 171.8553 - val_mae: 9.9893\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 259ms/step - loss: 282.3941 - mae: 11.2649 - val_loss: 135.7111 - val_mae: 9.6735\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 212.0005 - mae: 11.4655 - val_loss: 268.2285 - val_mae: 10.2265\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 265.5356 - mae: 12.2674 - val_loss: 102.6241 - val_mae: 10.8029\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 224.6067 - mae: 13.1989 - val_loss: 168.9607 - val_mae: 10.9844\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 237.6510 - mae: 13.1895 - val_loss: 107.1153 - val_mae: 10.8422\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 234.7802 - mae: 12.8708 - val_loss: 170.2330 - val_mae: 11.9372\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 190.2343 - mae: 13.7462 - val_loss: 85.8481 - val_mae: 12.5061\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 185.6084 - mae: 14.2504 - val_loss: 72.6493 - val_mae: 12.7684\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 165.2983 - mae: 14.6304 - val_loss: 86.3029 - val_mae: 12.2903\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 158.9211 - mae: 13.9094 - val_loss: 120.0259 - val_mae: 11.8017\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 141.5491 - mae: 13.3278 - val_loss: 92.9009 - val_mae: 11.4741\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 136.9546 - mae: 13.1622 - val_loss: 95.2703 - val_mae: 11.4575\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 234ms/step - loss: 137.6945 - mae: 13.1670 - val_loss: 64.6021 - val_mae: 11.3068\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 121.5847 - mae: 12.9038 - val_loss: 87.2340 - val_mae: 11.2243\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 115.1468 - mae: 12.9461 - val_loss: 113.9345 - val_mae: 11.1716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26be83d2bc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using GRU ###\n",
    "\n",
    "# Define the model\n",
    "model_gru = keras.Sequential()\n",
    "\n",
    "# Add a GRU layer\n",
    "model_gru.add(layers.GRU(128, input_shape=(timesteps, num_features_train)))\n",
    "model_gru.add(layers.Dropout(0.5))\n",
    "\n",
    "# Add a Dense layer\n",
    "model_gru.add(layers.Dense(y_train.shape[1]))\n",
    "\n",
    "# Display the model summary\n",
    "print(model_gru.summary())\n",
    "\n",
    "# Compile the model\n",
    "batch_size = 64\n",
    "model_gru.compile(\n",
    "    loss=keras.losses.MeanAbsolutePercentageError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "    metrics=[\"mae\"],\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model_gru.fit(\n",
    "    data_train_3D,\n",
    "    y_train[:num_sequences_train],\n",
    "    validation_data=(data_test_3D, y_test[:num_sequences_test]),\n",
    "    batch_size=batch_size,\n",
    "    epochs=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air_quality_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
